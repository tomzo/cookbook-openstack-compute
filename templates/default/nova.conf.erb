<%= node["openstack"]["compute"]["custom_template_banner"] %>

[DEFAULT]

# LOGS/STATE
debug=<%= node["openstack"]["compute"]["debug"] %>
verbose=<%= node["openstack"]["compute"]["verbose"] %>
auth_strategy=<%= node["openstack"]["compute"]["api"]["auth_strategy"] %>
dhcpbridge_flagfile=/etc/nova/nova.conf
dhcpbridge=/usr/bin/nova-dhcpbridge
log_dir=<%= node["openstack"]["compute"]["log_dir"] %>
<% if node["openstack"]["compute"]["syslog"]["use"] %>
log_config = /etc/openstack/logging.conf
<% end %>
state_path=<%= node["openstack"]["compute"]["state_path"] %>
instances_path=<%= node["openstack"]["compute"]["instances_path"] %>
instance_name_template=<%= node["openstack"]["compute"]["instance_name_template"] %>
network_allocate_retries=<%= node['openstack']['compute']['network_allocate_retries'] %>
lock_path=<%= node["openstack"]["compute"]["lock_path"] %>

ssl_only=<%= node['openstack']['compute']['ssl_only'] %>
cert=<%= node['openstack']['compute']['cert'] %>
key=<%= node['openstack']['compute']['key'] %>

# Command prefix to use for running commands as root (default: sudo)
rootwrap_config=/etc/nova/rootwrap.conf

# Should unused base images be removed? (default: false)
remove_unused_base_images=<%= node["openstack"]["compute"]["libvirt"]["remove_unused_base_images"] %>

# Unused unresized base images younger than this will not be removed (default: 86400)
remove_unused_original_minimum_age_seconds=<%= node["openstack"]["compute"]["libvirt"]["remove_unused_original_minimum_age_seconds"] %>

# Options defined in nova.openstack.common.rpc
rpc_thread_pool_size=<%= node["openstack"]["compute"]["rpc_thread_pool_size"] %>
rpc_conn_pool_size=<%= node["openstack"]["compute"]["rpc_conn_pool_size"] %>
rpc_response_timeout=<%= node["openstack"]["compute"]["rpc_response_timeout"] %>
rpc_backend=<%= node["openstack"]["compute"]["rpc_backend"] %>
amqp_durable_queues=<%= node['openstack']['mq']['compute']['durable_queues'] %>
amqp_auto_delete=<%= node['openstack']['mq']['compute']['auto_delete'] %>

<% if @mq_service_type == "rabbitmq"  %>
##### RABBITMQ #####
rabbit_userid=<%= node["openstack"]["mq"]["compute"]["rabbit"]["userid"] %>
rabbit_password=<%= @mq_password %>
rabbit_virtual_host=<%= node["openstack"]["mq"]["compute"]["rabbit"]["vhost"] %>
<% if node["openstack"]["mq"]["compute"]["rabbit"]["ha"] -%>
rabbit_hosts=<%= @rabbit_hosts %>
rabbit_ha_queues=True
rabbit_use_ssl=<%= node["openstack"]["mq"]["compute"]["rabbit"]["use_ssl"] %>
<% else -%>
rabbit_host=<%= node["openstack"]["mq"]["compute"]["rabbit"]["host"] %>
rabbit_port=<%= node["openstack"]["mq"]["compute"]["rabbit"]["port"] %>
rabbit_use_ssl=<%= node["openstack"]["mq"]["compute"]["rabbit"]["use_ssl"] %>
<% end -%>
<% end -%>

<% if @mq_service_type == "qpid"  %>
##### QPID #####
qpid_hostname=<%= node["openstack"]["mq"]["compute"]["qpid"]["host"] %>
qpid_port=<%= node["openstack"]["mq"]["compute"]["qpid"]["port"] %>
qpid_password=<%= @mq_password %>
qpid_username=<%= node["openstack"]["mq"]["compute"]["qpid"]["username"] %>
qpid_sasl_mechanisms=<%= node["openstack"]["mq"]["compute"]["qpid"]["sasl_mechanisms"] %>
qpid_reconnect_timeout=<%= node["openstack"]["mq"]["compute"]["qpid"]["reconnect_timeout"] %>
qpid_reconnect_limit=<%= node["openstack"]["mq"]["compute"]["qpid"]["reconnect_limit"] %>
qpid_reconnect_interval_min=<%= node["openstack"]["mq"]["compute"]["qpid"]["reconnect_interval_min"] %>
qpid_reconnect_interval_max=<%= node["openstack"]["mq"]["compute"]["qpid"]["reconnect_interval_max"] %>
qpid_reconnect_interval=<%= node["openstack"]["mq"]["compute"]["qpid"]["reconnect_interval"] %>
qpid_heartbeat=<%= node["openstack"]["mq"]["compute"]["qpid"]["heartbeat"] %>
# qpid protocol. default 'tcp'. set to 'ssl' to enable SSL
qpid_protocol=<%= node["openstack"]["mq"]["compute"]["qpid"]["protocol"] %>
qpid_tcp_nodelay=<%= node["openstack"]["mq"]["compute"]["qpid"]["tcp_nodelay"] %>
qpid_topology_version=<%= node['openstack']['mq']['compute']['qpid']['topology_version'] %>
<% end %>


##### SCHEDULER #####
scheduler_manager=<%= node["openstack"]["compute"]["scheduler"]["scheduler_manager"] %>
scheduler_driver=<%= node["openstack"]["compute"]["scheduler"]["scheduler_driver"] %>
scheduler_available_filters=<%= node["openstack"]["compute"]["scheduler"]["available_filters"] %>
# which filter class names to use for filtering hosts when not specified in the request.
scheduler_default_filters=<%= @scheduler_default_filters %>
default_availability_zone=<%= node["openstack"]["compute"]["config"]["availability_zone"] %>
default_schedule_zone=<%= node["openstack"]["compute"]["config"]["default_schedule_zone"] %>

##### NETWORK #####

dhcp_domain=""

<% case node["openstack"]["compute"]["network"]["service_type"]

when "neutron" -%>

network_api_class=<%= node["openstack"]["compute"]["network"]["neutron"]["network_api_class"]  %>
linuxnet_interface_driver=<%= node["openstack"]["compute"]["network"]["neutron"]["linuxnet_interface_driver"] %>
firewall_driver = nova.virt.firewall.NoopFirewallDriver
security_group_api=<%= node["openstack"]["compute"]["network"]["neutron"]["security_group_api"] %>
default_floating_pool=<%= node["openstack"]["compute"]["network"]["neutron"]["public_network_name"] %>
dns_server=<%= node["openstack"]["compute"]["network"]["neutron"]["dns_server"] %>

<% when "nova" -%>
multi_host=<%= node["openstack"]["compute"]["network"]["multi_host"] %>
network_manager=<%= node["openstack"]["compute"]["network"]["network_manager"] %>
public_interface=<%= node["openstack"]["compute"]["network"]["public_interface"] %>
dmz_cidr=<%= node["openstack"]["compute"]["network"]["dmz_cidr"] %>
force_dhcp_release=<%= node["openstack"]["compute"]["network"]["force_dhcp_release"] %>
<% if node["openstack"]["compute"]["dhcp_domain"] -%>
dhcp_domain=<%= node["openstack"]["compute"]["dhcp_domain"] %>
<% end %>
send_arp_for_ha=true
use_single_default_gateway=<%= node["openstack"]["compute"]["network"]["use_single_default_gateway"] %>
vlan_interface=<%= node["openstack"]["compute"]["network"]["vlan_interface"] %>
auto_assign_floating_ip=<%= node["openstack"]["compute"]["network"]["auto_assign_floating_ip"] %>
<% end -%>
use_ipv6=<%= node["openstack"]["compute"]["network"]["use_ipv6"] %>

##### GLANCE #####
image_service=nova.image.glance.GlanceImageService

##### COMPUTE #####
compute_driver=<%= node["openstack"]["compute"]["driver"] %>
<% if node["openstack"]["compute"]["default_ephemeral_format"] %>
default_ephemeral_format=<%= node["openstack"]["compute"]["default_ephemeral_format"] %>
<% end %>
preallocate_images=<%= node["openstack"]["compute"]["preallocate_images"] %>
use_cow_images=<%= node["openstack"]["compute"]["use_cow_images"] %>
vif_plugging_is_fatal=<%= node["openstack"]["compute"]["vif_plugging_is_fatal"] %>
vif_plugging_timeout=<%= node["openstack"]["compute"]["vif_plugging_timeout"] %>
compute_manager=<%= node["openstack"]["compute"]["manager"] %>
sql_connection=<%= @sql_connection %>
connection_type=libvirt

##### NOTIFICATIONS #####
<% if node['openstack']['compute']['config']['notification_drivers'] %>
# Driver or drivers to handle sending notifications (multi valued)
<% node['openstack']['compute']['config']['notification_drivers'].each do |d| %>
notification_driver=<%= d %>
<% end %>
<% end %>

<% if node['openstack']['compute']['config']['notification_topics'] %>
# AMQP topic used for OpenStack notifications. (list value)
# Deprecated group/name - [rpc_notifier2]/topics
notification_topics=<%= node['openstack']['compute']['config']['notification_topics'].join(",") %>
<% end %>

# Generate periodic compute.instance.exists notifications
instance_usage_audit=<%= node['openstack']['compute']['config']['instance_usage_audit'] %>

# Time period to generate instance usages for.  Time period
# must be hour, day, month or year (string value)
instance_usage_audit_period=<%= node['openstack']['compute']['config']['instance_usage_audit_period'] %>

<% unless node['openstack']['compute']['config']['notify_on_state_change'].empty? -%>
# If set, send compute.instance.update notifications on
# instance state changes.  Valid values are None for no
# notifications, "vm_state" for notifications on VM state
# changes, or "vm_and_task_state" for notifications on VM and
# task state changes. (string value)
notify_on_state_change=<%= node['openstack']['compute']['config']['notify_on_state_change'] %>
<% end %>

<% if node["openstack"]["compute"]["enabled_apis"].include?("osapi_compute") -%>
# The IP address on which the OpenStack API will listen. (string value)
osapi_compute_listen=<%= @compute_api_bind_ip %>
# The port on which the OpenStack API will listen. (integer value)
osapi_compute_listen_port=<%= @compute_api_bind_port %>
<% end -%>

# The IP address on which the metadata will listen. (string value)
metadata_listen=<%= @compute_metadata_api_bind_ip %>
# The port on which the metadata will listen. (integer value)
metadata_listen_port=<%= @compute_metadata_api_bind_port %>

##### VNCPROXY #####
<% if node['openstack']['compute']['vnc']['enabled'] %>
novncproxy_base_url=<%= @novncproxy_base_url %>
xvpvncproxy_base_url=<%= @xvpvncproxy_base_url %>

# This is only required on the server running xvpvncproxy
xvpvncproxy_host=<%= @xvpvncproxy_bind_host %>
xvpvncproxy_port=<%= @xvpvncproxy_bind_port %>

# This is only required on the server running novncproxy
novncproxy_host=<%= @novncproxy_bind_host %>
novncproxy_port=<%= @novncproxy_bind_port %>

vncserver_listen=<%= @vncserver_listen %>
vncserver_proxyclient_address=<%= @vncserver_proxyclient_address %>

vnc_keymap=<%= node['openstack']['compute']['vnc']['keymap'] %>
<% else %>
vnc_enabled=False
<% end %>

# store consoleauth tokens in memcached
<% unless @memcache_servers.empty? -%>
memcached_servers=<%= @memcache_servers %>
<% end -%>

##### MISC #####
# force backing images to raw format
force_raw_images=<%= node["openstack"]["compute"]["config"]["force_raw_images"] %>
allow_same_net_traffic=<%= node["openstack"]["compute"]["config"]["allow_same_net_traffic"] %>
osapi_max_limit=<%= node["openstack"]["compute"]["config"]["osapi_max_limit"] %>
# If you terminate SSL with a load balancer, the HTTP_HOST environ
# variable that generates the request_uri in webob.Request will lack
# the HTTPS scheme. Setting this overrides the default and allows
# URIs returned in the various links collections to contain the proper
# HTTPS endpoint.
osapi_compute_link_prefix = <%= @osapi_compute_link_prefix %>
start_guests_on_host_boot=<%= node["openstack"]["compute"]["config"]["start_guests_on_host_boot"] %>
resume_guests_state_on_host_boot=<%= node["openstack"]["compute"]["config"]["resume_guests_state_on_host_boot"] %>
allow_resize_to_same_host=<%= node["openstack"]["compute"]["config"]["allow_resize_to_same_host"] %>
resize_confirm_window=<%= node["openstack"]["compute"]["config"]["resize_confirm_window"] %>
live_migration_retry_count=<%= node["openstack"]["compute"]["config"]["live_migration_retry_count"] %>

##### QUOTAS #####
# (StrOpt) default driver to use for quota checks (default: nova.quota.DbQuotaDriver)
quota_driver=<%= node["openstack"]["compute"]["config"]["quota_driver"] %>
# number of security groups per project (default: 10)
quota_security_groups=<%= node["openstack"]["compute"]["config"]["quota_security_groups"] %>
# number of security rules per security group (default: 20)
quota_security_group_rules=<%= node["openstack"]["compute"]["config"]["quota_security_group_rules"] %>
# number of instance cores allowed per project (default: 20)
quota_cores=<%= node["openstack"]["compute"]["config"]["quota_cores"] %>
# number of fixed ips allowed per project (this should be at least the number of instances allowed) (default: -1)
quota_fixed_ips=<%= node["openstack"]["compute"]["config"]["quota_fixed_ips"] %>
# number of floating ips allowed per project (default: 10)
quota_floating_ips=<%= node["openstack"]["compute"]["config"]["quota_floating_ips"] %>
# number of bytes allowed per injected file (default: 10240)
quota_injected_file_content_bytes=<%= node["openstack"]["compute"]["config"]["quota_injected_file_content_bytes"] %>
# number of bytes allowed per injected file path (default: 255)
quota_injected_file_path_length=<%= node["openstack"]["compute"]["config"]["quota_injected_file_path_length"] %>
# number of injected files allowed (default: 5)
quota_injected_files=<%= node["openstack"]["compute"]["config"]["quota_injected_files"] %>
# number of instances allowed per project (defailt: 10)
quota_instances=<%= node["openstack"]["compute"]["config"]["quota_instances"] %>
# number of key pairs per user (default: 100)
quota_key_pairs=<%= node["openstack"]["compute"]["config"]["quota_key_pairs"] %>
# number of metadata items allowed per instance (default: 128)
quota_metadata_items=<%= node["openstack"]["compute"]["config"]["quota_metadata_items"] %>
# megabytes of instance ram allowed per project (default: 51200)
quota_ram=<%= node["openstack"]["compute"]["config"]["quota_ram"] %>

<%- if /ComputeFilter/.match(@scheduler_default_filters) %>
# virtual CPU to Physical CPU allocation ratio (default: 16.0)
cpu_allocation_ratio=<%= node["openstack"]["compute"]["config"]["cpu_allocation_ratio"] %>
<%- end %>
<%- if /RamFilter/.match(@scheduler_default_filters) %>
# virtual ram to physical ram allocation ratio (default: 1.5)
ram_allocation_ratio=<%= node["openstack"]["compute"]["config"]["ram_allocation_ratio"] %>
<%- end %>
<%- if /DiskFilter/.match(@scheduler_default_filters) %>
# virtual disk to physical disk allocation ratio (default: 1.0)
disk_allocation_ratio=<%= node["openstack"]["compute"]["config"]["disk_allocation_ratio"] %>
<%- end %>

<% if node["openstack"]["compute"]["config"]["force_config_drive"] %>
force_config_drive=<%= node["openstack"]["compute"]["config"]["force_config_drive"] %>
<% end %>
mkisofs_cmd=<%= node["openstack"]["compute"]["config"]["mkisofs_cmd"] %>
injected_network_template=<%= node["openstack"]["compute"]["config"]["injected_network_template"] %>
flat_injected=<%= node["openstack"]["compute"]["config"]["flat_injected"] %>

<% if node["openstack"]["compute"]["enabled_apis"].include?("ec2") %>
# The IP address on which the EC2 API will listen. (string value)
ec2_listen=<%= @ec2_api_bind_ip %>
# The port on which the EC2 API will listen. (integer value)
ec2_listen_port=<%= @ec2_api_bind_port %>

<% if %w(fedora rhel).include? node.platform_family -%>
# Adding support for non-modded euca2ools to display ip address info
# https://bugs.launchpad.net/nova/+bug/901594
ec2_private_dns_show_ip=True
<% end -%>

##### WORKERS ######
<% if node["openstack"]["compute"]["ec2_workers"] %>
ec2_workers=<%= node["openstack"]["compute"]["ec2_workers"] %>
<% end %>

##### KEYSTONE #####
keystone_ec2_url=<%= @identity_endpoint.scheme %>://<%= @identity_endpoint.host %>:<%= @identity_endpoint.port %>/v2.0/ec2tokens
<% end -%>

# a list of APIs to enable by default (list value)
enabled_apis=<%= node["openstack"]["compute"]["enabled_apis"] %>

##### WORKERS ######
<% if node["openstack"]["compute"]["osapi_compute_workers"] %>
osapi_compute_workers=<%= node["openstack"]["compute"]["osapi_compute_workers"] %>
<% end %>
<% if node["openstack"]["compute"]["metadata_workers"] %>
metadata_workers=<%= node["openstack"]["compute"]["metadata_workers"] %>
<% end %>

##### MONITORS ######
<% node['openstack']['compute']['config']['compute_available_monitors'].each do |m| %>
# Monitor classes available to the compute which may be
# specified more than once. (multi valued)
compute_available_monitors=<%= m %>
<% end %>

<% if node["openstack"]["compute"]["config"]["compute_monitors"] %>
# A list of monitors that can be used for getting compute
# metrics. (list value)
compute_monitors=<%= node["openstack"]["compute"]["config"]["compute_monitors"].join(",") %>
<% end %>

##### VOLUMES #####
# iscsi target user-land tool to use
iscsi_helper=<%= @iscsi_helper %>
volume_api_class=<%= node["openstack"]["compute"]["config"]["volume_api_class"] %>

# Override the default dnsmasq settings with this file (String value)
dnsmasq_config_file=<%= node['openstack']['compute']['dnsmasq_config_file'] %>

##### THIRD PARTY ADDITIONS #####
<% if node["openstack"]["compute"]["plugins"] %>
<% node["openstack"]["compute"]["plugins"].each do |p| %>
osapi_compute_extension=<%= p %>
<% end %>
<% end %>

<% if node["openstack"]["compute"]["misc_nova"] %>
<% node["openstack"]["compute"]["misc_nova"].each do |m| %>
<%= m %>
<% end %>
<% end %>

[ssl]

# CA certificate file to use to verify connecting clients
ca_file=<%= node['openstack']['compute']['image']['ssl']['ca_file'] %>

# Certificate file to use when starting the server securely
cert_file=<%= node['openstack']['compute']['image']['ssl']['cert_file'] %>

# Private key file to use when starting the server securely
key_file=<%= node['openstack']['compute']['image']['ssl']['key_file'] %>

[conductor]

use_local=<%= node["openstack"]["compute"]["conductor"]["use_local"] %>
<% if node["openstack"]["compute"]["conductor"]["workers"] %>
workers=<%= node["openstack"]["compute"]["conductor"]["workers"] %>
<% end %>

<% if %w(vmwareapi.VMwareESXDriver vmwareapi.VMwareVCDriver).include?(node['openstack']['compute']['driver']) %>
[vmware]

#
# Options defined in nova.virt.vmwareapi.driver
#

# URL for connection to VMware ESX/VC host. (string value)
host_ip = <%= node['openstack']['compute']['vmware']['host_ip'] %>

# Username for connection to VMware ESX/VC host. (string
# value)
host_username = <%= node['openstack']['compute']['vmware']['host_username'] %>

# Password for connection to VMware ESX/VC host. (string
# value)
host_password = <%= @vmware_host_pass %>

<% if node['openstack']['compute']['vmware']['cluster_name'] %>
# Name of a VMware Cluster ComputeResource. Used only if
# compute_driver is vmwareapi.VMwareVCDriver. (multi valued)
  <% node['openstack']['compute']['vmware']['cluster_name'].each do |cluster| %>
cluster_name = <%= cluster %>
  <% end %>
<% end %>

<% if node['openstack']['compute']['vmware']['datastore_regex'] %>
# Regex to match the name of a datastore. (string value)
datastore_regex = <%= node['openstack']['compute']['vmware']['datastore_regex'] %>
<% end %>

# The interval used for polling of remote tasks. (floating
# point value)
task_poll_interval = <%= node['openstack']['compute']['vmware']['task_poll_interval'] %>

# The number of times we retry on failures, e.g., socket
# error, etc. (integer value)
api_retry_count = <%= node['openstack']['compute']['vmware']['api_retry_count'] %>

# VNC starting port (integer value)
vnc_port = <%= node['openstack']['compute']['vmware']['vnc_port'] %>

# Total number of VNC ports (integer value)
vnc_port_total = <%= node['openstack']['compute']['vmware']['vnc_port_total'] %>

# Whether to use linked clone (boolean value)
use_linked_clone = <%= node['openstack']['compute']['vmware']['use_linked_clone'] %>


#
# Options defined in nova.virt.vmwareapi.vif
#

# Physical ethernet adapter name for vlan networking (string
# value)
vlan_interface = <%= node['openstack']['compute']['vmware']['vlan_interface'] %>


<% if node['openstack']['compute']['vmware']['wsdl_location'] %>
#
# Options defined in nova.virt.vmwareapi.vim
#
# Optional VIM Service WSDL Location e.g
# http://<server>/vimService.wsdl. Optional over-ride to
# default location for bug work-arounds (string value)
wsdl_location = <%= node['openstack']['compute']['vmware']['wsdl_location'] %>
<% end %>

#
# Options defined in nova.virt.vmwareapi.vim_util
#

# The maximum number of ObjectContent data objects that should
# be returned in a single result. A positive value will cause
# the operation to suspend the retrieval when the count of
# objects reaches the specified maximum. The server may still
# limit the count to something less than the configured value.
# Any remaining objects may be retrieved with additional
# requests. (integer value)
maximum_objects = <%= node['openstack']['compute']['vmware']['maximum_objects'] %>


#
# Options defined in nova.virt.vmwareapi.vmops
#

# Name of Integration Bridge (string value)
integration_bridge = <%= node['openstack']['compute']['vmware']['integration_bridge'] %>
<% end %>

[libvirt]

#
# Options defined in nova.virt.libvirt.driver
#

# Rescue ami image (string value)
#rescue_image_id=<None>

# Rescue aki image (string value)
#rescue_kernel_id=<None>

# Rescue ari image (string value)
#rescue_ramdisk_id=<None>

# Libvirt domain type (valid options are: kvm, lxc, qemu, uml,
# xen) (string value)
# Deprecated group/name - [DEFAULT]/libvirt_type
virt_type=<%= node["openstack"]["compute"]["libvirt"]["virt_type"] %>

# Override the default libvirt URI (which is dependent on
# virt_type) (string value)
# Deprecated group/name - [DEFAULT]/libvirt_uri
#connection_uri=

# Inject the admin password at boot time, without an agent.
# (boolean value)
# Deprecated group/name - [DEFAULT]/libvirt_inject_password
inject_password=<%= node["openstack"]["compute"]["libvirt"]["libvirt_inject_password"] %>

# Inject the ssh public key at boot time (boolean value)
# Deprecated group/name - [DEFAULT]/libvirt_inject_key
inject_key=<%= node["openstack"]["compute"]["libvirt"]["libvirt_inject_key"] %>

# The partition to inject to : -2 => disable, -1 => inspect
# (libguestfs only), 0 => not partitioned, >0 => partition
# number (integer value)
# Deprecated group/name - [DEFAULT]/libvirt_inject_partition
inject_partition=<%= node["openstack"]["compute"]["libvirt"]["libvirt_inject_partition"] %>

# Sync virtual and real mouse cursors in Windows VMs (boolean
# value)
#use_usb_tablet=true

# Migration target URI (any included "%s" is replaced with the
# migration target hostname) (string value)
live_migration_uri=<%= node["openstack"]["compute"]["libvirt"]["live_migration_uri"] %>

# Migration flags to be set for live migration (string value)
live_migration_flag=<%= node["openstack"]["compute"]["libvirt"]["live_migration_flag"] %>

# Migration flags to be set for block migration (string value)
block_migration_flag=<%= node["openstack"]["compute"]["libvirt"]["block_migration_flag"] %>

# Maximum bandwidth to be used during migration, in Mbps
# (integer value)
live_migration_bandwidth=<%= node["openstack"]["compute"]["libvirt"]["live_migration_bandwidth"] %>

# Snapshot image format (valid options are : raw, qcow2, vmdk,
# vdi). Defaults to same as source image (string value)
snapshot_image_format=<%= node["openstack"]["compute"]["config"]["snapshot_image_format"] %>

# The libvirt VIF driver to configure the VIFs. (string value)
# Deprecated group/name - [DEFAULT]/libvirt_vif_driver
vif_driver=<%= node["openstack"]["compute"]["network"]["neutron"]["libvirt_vif_driver"] %>

# Libvirt handlers for remote volumes. (list value)
# Deprecated group/name - [DEFAULT]/libvirt_volume_drivers
#volume_drivers=iscsi=nova.virt.libvirt.volume.LibvirtISCSIVolumeDriver,iser=nova.virt.libvirt.volume.LibvirtISERVolumeDriver,local=nova.virt.libvirt.volume.LibvirtVolumeDriver,fake=nova.virt.libvirt.volume.LibvirtFakeVolumeDriver,rbd=nova.virt.libvirt.volume.LibvirtNetVolumeDriver,sheepdog=nova.virt.libvirt.volume.LibvirtNetVolumeDriver,nfs=nova.virt.libvirt.volume.LibvirtNFSVolumeDriver,aoe=nova.virt.libvirt.volume.LibvirtAOEVolumeDriver,glusterfs=nova.virt.libvirt.volume.LibvirtGlusterfsVolumeDriver,fibre_channel=nova.virt.libvirt.volume.LibvirtFibreChannelVolumeDriver,scality=nova.virt.libvirt.volume.LibvirtScalityVolumeDriver

# Override the default disk prefix for the devices attached to
# a server, which is dependent on virt_type. (valid options
# are: sd, xvd, uvd, vd) (string value)
# Deprecated group/name - [DEFAULT]/libvirt_disk_prefix
#disk_prefix=<None>

# Number of seconds to wait for instance to shut down after
# soft reboot request is made. We fall back to hard reboot if
# instance does not shutdown within this window. (integer
# value)
# Deprecated group/name - [DEFAULT]/libvirt_wait_soft_reboot_seconds
#wait_soft_reboot_seconds=120

# Set to "host-model" to clone the host CPU feature flags; to
# "host-passthrough" to use the host CPU model exactly; to
# "custom" to use a named CPU model; to "none" to not set any
# CPU model. If virt_type="kvm|qemu", it will default to
# "host-model", otherwise it will default to "none" (string
# value)
# Deprecated group/name - [DEFAULT]/libvirt_cpu_mode
<% if node["openstack"]["compute"]["libvirt"]["virt_type"] == "qemu" -%>
cpu_mode=none
<% end -%>

# Set to a named libvirt CPU model (see names listed in
# /usr/share/libvirt/cpu_map.xml). Only has effect if
# cpu_mode="custom" and virt_type="kvm|qemu" (string value)
# Deprecated group/name - [DEFAULT]/libvirt_cpu_model
#cpu_model=<none>

# Location where libvirt driver will store snapshots before
# uploading them to image service (string value)
# Deprecated group/name - [DEFAULT]/libvirt_snapshots_directory
#snapshots_directory=$instances_path/snapshots

# Location where the Xen hvmloader is kept (string value)
#xen_hvmloader_path=/usr/lib/xen/boot/hvmloader

# Specific cachemodes to use for different disk types e.g:
# file=directsync,block=none (list value)
disk_cachemodes=<%= node["openstack"]["compute"]["config"]["disk_cachemodes"] %>

# A path to a device that will be used as source of entropy on
# the host. Permitted options are: /dev/random or /dev/hwrng
# (string value)
<% if node["openstack"]["compute"]["libvirt"]["rng_dev_path"] -%>
rng_dev_path=<%= node["openstack"]["compute"]["libvirt"]["rng_dev_path"] %>
<% end -%>

#
# Options defined in nova.virt.libvirt.imagecache
#

# Unused resized base images younger than this will not be removed (default: 3600)
remove_unused_resized_minimum_age_seconds=<%= node["openstack"]["compute"]["libvirt"]["remove_unused_resized_minimum_age_seconds"] %>

# Write a checksum for files in _base to disk (default: false)
checksum_base_images=<%= node["openstack"]["compute"]["libvirt"]["checksum_base_images"] %>

#
# Options defined in nova.virt.libvirt.vif
#

<% if node["openstack"]["compute"]["libvirt"]["virt_type"] == "qemu" -%>
use_virtio_for_bridges=false
<% else -%>
use_virtio_for_bridges=true
<% end -%>

#
# Options defined in nova.virt.libvirt.imagebackend
#

# VM Images format. Acceptable values are: raw, qcow2, lvm, rbd, default. If default is specified,
# then use_cow_images flag is used instead of this one.
images_type=<%= node['openstack']['compute']['libvirt']['images_type'] %>

<% if node['openstack']['compute']['libvirt']['images_type'] == 'lvm' -%>
images_volume_group=<%= node['openstack']['compute']['libvirt']['volume_group'] %>
sparse_logical_volumes=<%= node['openstack']['compute']['libvirt']['sparse_logical_volumes'] %>

<% elsif node['openstack']['compute']['libvirt']['images_type'] == 'rbd' -%>
# This a pool where ephemeral disks for nova are stored
# They are a cheap COW with parents in node['openstack']['compute']['libvirt']['rbd']['glance']['pool']
images_rbd_pool=<%= node['openstack']['compute']['libvirt']['rbd']['nova']['pool'] %>
images_rbd_ceph_conf=<%= node['openstack']['compute']['libvirt']['rbd']['ceph_conf'] %>

#
# Options defined in nova.virt.libvirt.volume
#

# The RADOS client name for accessing rbd volumes (string value)
# NOTE that if these two options are set here, it will override the rbd_user that cinder provides
# for nova in netdisk_properties:
# https://github.com/openstack/nova/blob/c15dff2e9978fe851c73e92ab7f9b46e27de81ba/nova/virt/libvirt/volume.py#L217-L229
rbd_user=<%= node['openstack']['compute']['libvirt']['rbd']['cinder']['user'] %>
# The libvirt UUID of the secret for the rbd images (string value)
rbd_secret_uuid=<%= node['openstack']['compute']['libvirt']['rbd']['cinder']['secret_uuid'] %>
<% end -%>

[keystone_authtoken]
auth_uri = <%= @auth_uri %>
auth_host = <%= @identity_admin_endpoint.host %>
auth_port = <%= @identity_admin_endpoint.port %>
auth_protocol = <%= @identity_admin_endpoint.scheme %>
auth_version = <%= node["openstack"]["compute"]["api"]["auth"]["version"] %>
admin_tenant_name = <%= node["openstack"]["compute"]["service_tenant_name"] %>
admin_user = <%= node["openstack"]["compute"]["service_user"] %>
admin_password = <%= @service_pass %>
signing_dir = <%= node["openstack"]["compute"]["api"]["auth"]["cache_dir"] %>
<% unless node['openstack']['compute']['api']['auth']['cafile'].nil? %>
cafile = <%= node['openstack']['compute']['api']['auth']['cafile'] %>
<% end %>
<% unless node['openstack']['compute']['api']['auth']['memcached_servers'].nil? %>
memcached_servers = <%= node['openstack']['compute']['api']['auth']['memcached_servers'] %>
<% end %>
<% unless node['openstack']['compute']['api']['auth']['memcache_security_strategy'].nil? %>
memcache_security_strategy = <%= node['openstack']['compute']['api']['auth']['memcache_security_strategy'] %>
<% end %>
<% unless node['openstack']['compute']['api']['auth']['memcache_secret_key'].nil? %>
memcache_secret_key = <%= node['openstack']['compute']['api']['auth']['memcache_secret_key'] %>
<% end %>
hash_algorithms = <%= node['openstack']['compute']['api']['auth']['hash_algorithms'] %>
insecure = <%= node['openstack']['compute']['api']['auth']['insecure'] %>

<% if node['openstack']['compute']['network']['service_type'] == 'neutron' %>

[neutron]
# N.B. due to https://bugs.launchpad.net/nova/+bug/1206330
# we override the endpoint scheme below, ignore the port
# and essentially force http
<% if @network_endpoint.port == 443 -%>
url=http://<%= @network_endpoint.host %>:80
<% else -%>
url=<%= @network_endpoint.scheme %>://<%= @network_endpoint.host %>:<%= @network_endpoint.port %>
<% end -%>
api_insecure=<%= node['openstack']['compute']['network']['neutron']['api_insecure'] %>
auth_strategy=<%= node["openstack"]["compute"]["network"]["neutron"]["auth_strategy"] %>
admin_tenant_name=<%= node["openstack"]["compute"]["network"]["neutron"]["admin_tenant_name"] %>
admin_username=<%= node["openstack"]["compute"]["network"]["neutron"]["admin_username"] %>
admin_password=<%= @neutron_admin_password %>
admin_auth_url=<%= @identity_endpoint.to_s %>
url_timeout=<%= node["openstack"]["compute"]["network"]["neutron"]["url_timeout"] %>
region_name=<%= node["openstack"]["compute"]["network"]["neutron"]["region_name"] %>
ovs_bridge=<%= node["openstack"]["compute"]["network"]["neutron"]["ovs_bridge"] %>
extension_sync_interval=<%= node["openstack"]["compute"]["network"]["neutron"]["extension_sync_interval"] %>
ca_certificates_file=<%= node["openstack"]["compute"]["network"]["neutron"]["ca_certificates_file"] %>
service_metadata_proxy=<%= node["openstack"]["compute"]["network"]["neutron"]["service_neutron_metadata_proxy"] %>
metadata_proxy_shared_secret=<%= @neutron_metadata_proxy_shared_secret %>

<% end %>

[glance]
api_servers=<%= @glance_api_scheme %>://<%= @glance_api_ipaddress %>:<%= @glance_api_port %>
api_insecure=<%= node['openstack']['compute']['image']['glance_api_insecure'] %>

[cinder]
# Location of ca certificates file to use for cinder client requests
ca_certificates_file=<%= node['openstack']['compute']['block-storage']['cinder_ca_certificates_file'] %>

# Allow to perform insecure SSL requests to cinder
api_insecure=<%= node['openstack']['compute']['block-storage']['cinder_api_insecure'] %>

# Info to match when looking for cinder in the service catalog
catalog_info=<%= node['openstack']['compute']['block-storage']['cinder_catalog_info'] %>

# Region name of this node (string value)
os_region_name=<%= node['openstack']['region'] %>

<% if node['openstack']['compute']['upgrade_levels'] -%>
# Lock the version of RPC messages and allow live upgrading of the services
# without interruption caused by version mismatch.
# Add upgrade_levels for order rpc API, ex. compute = juno
[upgrade_levels]
<% node['openstack']['compute']['upgrade_levels'].each do |key, val| %>
<%= key %> = <%= val %>
<% end -%>
<% end -%>

<% if node['openstack']['compute']['spice']['enabled'] %>
[spice]
enabled=True
agent_enabled=<%= node['openstack']['compute']['spice']['agent_enabled'] %>
html5proxy_base_url=<%= @html5proxy_base_url %>
html5proxy_host=<%= @html5proxy_bind_host %>
html5proxy_port=<%= @html5proxy_bind_port %>
keymap=<%= node['openstack']['compute']['spice']['keymap'] %>
server_listen=<%= @spice_server_listen %>
server_proxyclient_address=<%= @spice_server_proxyclient_address %>
<% end %>
